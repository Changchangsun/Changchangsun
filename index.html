<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">	
	<title>Changchang Sun</title>
	<meta content=Changchang Sun, changchangsun.github.io/Changchangsun" name="keywords">
	<link rel="stylesheet" href="./index_files/jemdoc.css" type="text/css">
	<script async="" src="http://www.google-analytics.com/analytics.js"></script>
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
		ga('create', 'UA-66888300-1', 'auto');
		ga('send', 'pageview');
	</script>
	<script type="text/javascript" src="./index_files/jquery-1.12.4.min.js"></script>
	<style>
	a {color: #2471a3; text-decoration: none;}
	a:hover {color: #5499c7;}
	a.btn {background-color: #2471a3; color: #fff; font-size: 12px; margin-top: 4px; display: inline-block; padding: 0 4px; border-radius: 2px; line-height: 1.5em;}
	a.btn:hover {background-color: #174e74;}
	a.btn.btn-red {background-color: #d63a3a;}
	a.btn.btn-red:hover {background-color: #a02727;}
	a.btn.btn-orange {background-color: #e2700c;}
	a.btn.btn-orange:hover {background-color: #c46009;}
	a.btn.btn-dark {background-color: #345;}
	a.btn.btn-dark:hover {background-color: #234;}
	p {line-height: 1.5em;}
	.nobreak {white-space: nowrap;}
	.noselect {-webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none;}
	.bold {font-weight: bold;}
	.italic {font-style: italic;}
	.bulletpoints {line-height: 1.5em;}
	.row {box-sizing: border-box;}
	.row-media {display: block; float: left; width: 180px; height: 90px; background-position: center; background-size: contain; background-repeat: no-repeat; border-radius: 6px; border: 1px solid #def;}
	.row-text {display: block; float: left; margin-left: 16px; line-height: 1.5em; max-width: 662px;}
	.row-text span {line-height: inherit;}
	.clearfix {content: ""; clear: both; display: table;}
	.publication {margin-bottom: 32px; margin-left: 16px;}
	.press {width: 100px; height: 80px; border: 1px solid #def; margin-right: 12px; background-size: cover;}  
	.img-contain {background-size: contain !important;}
	.footer {background-color: #345; width: 100%}
	.footer-content {color: #fff; font-size: 10px; padding: 6px 0; max-width: 900px; margin: auto;}

	@media only screen and (max-width: 1150px) {
		.header-profile-picture, .header-text {display: block; margin: auto; text-align: center;}
		.header-profile-picture {margin-bottom: 12px; width: 140px; height: 140px;}
		body {font-size: 18px;}
		a.btn {font-size: 14px; padding: 2px 6px;}
	}

	@media only screen and (max-width: 900px) {
		.publication {margin-bottom: 46px;}
		.publication .row-media {width: 260px; height: 130px; margin: auto; margin-bottom: 12px; display: block;}
		.publication .row-text {display: block; width: 100%; margin-left: 0;}
		.press {display: block;}
	}
    </style>
</head>


<body>
<div id="layout-content" style="margin-top:25px">

<table cellpadding="11px">
	<tbody>
		<tr>
			<td width="720px">
				<div id="toptitle">
					<h1>Changchang Sun (孙畅畅) &nbsp; </h1>
				</div>
                <h3>Ph.D. Student</h3>       
				<p>
					<!-- <a href="https://iitcvmlab.github.io/">CVM Lab @ UIC</a><br>  -->
					<a href="https://iitcvmlab.github.io/">CVM Lab @ UIC</a><br> 
					<a href="https://cs.uic.edu/">Department of Computer Science</a><br>
					<a href="https://www.uic.edu/">University of Illinois Chicago</a><br>
					851 S. Morgan St., 11th Floor SEO, Chicago, IL 60607, U.S.A <br>
					<br>
					Email:  sunchangchang123 at gmail dot com and csun47 at uic dot edu<br>
					<br>
					<a href="./files/Changchang_Sun_Academic_CV.pdf"> <img src="./files/logo-cv.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
					<a href="https://github.com/Changchangsun"> <img src="./files/logo-github.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
<!-- 					<a href="https://www.zhihu.com/people/Cogito2012"> <img src="./files/logo-zhihu.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a> -->
					<a href="https://scholar.google.com/citations?user=bCxWjjYAAAAJ&hl=zh-CN&oi=ao"> <img src="./files/logo-googlescholar.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
<!-- 					<a href="https://www.linkedin.com/in/wentao-bao-a59b88125"> <img src="./files/logo-linkin.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a> -->
                </p>
			</td>
			<td valign="middle">
				<img src="./files/scc.jpg" border="0" width="180"><br><br>
			</td>
		</tr>
	</tbody>
</table>

<h2>About Me</h2> 
	<p style="text-align:justify;">I am currently a fourth-year Ph.D. student (Jan.2025-) in the <a href="https://iitcvmlab.github.io/">Computer Vision and Multimedia Laboratory (CVMLab)</a>
	at the <a href="https://www.uic.edu/">University of Illinois Chicago (UIC)</a>, supervised by Prof. <a href="https://tomyan555.github.io/">Yan Yan</a>. Before join UIC (Aug.2021-Dec.2024), I studied  	
	at the <a href="https://www.iit.edu/">Illinois Institute of Technology (IIT)</a>, supervised by Prof. <a href="https://tomyan555.github.io/">Yan Yan</a>. 
		Currently, I am a visiting student (Aug.2023-) at Michigan State University under the supervision of Prof. <a href="https://lsjxjtu.github.io/">Sijia Liu</a>.
Before joining CVMLab, I received my Master and Bacherlor degrees from <a href="https://www.en.sdu.edu.cn/">Computer Science and Technology, Shandong University</a> in 2021 and 2018, supervised by Associate Professor <a href="https://xuemengsong.github.io/">Xuemeng Song</a>,
    and co-supervised by Professor <a href="https://liqiangnie.github.io/index.html"{>Liqiang Nie</a>.
<!-- 		I have research internship collaborations with excellent industrial researchers from Apple, OPPO US Research Center, and NEC Lab America.  -->
	</p>
	<p>I currently work on computer vision like human-object interaction detection, cross-modal generation and retrieval, machine unlearning. During the master's degree, I worked on information retrieval and machine learning.
<!-- 	<p style="text-align:justify;"><strong>I develop AI to understand the open visual world</strong>. To achieve this goal, I am broadly interested in using images/videos/text to solve real-world challenges including the visual recognition, prediction, understanding, and reasoning. My research works are related to <strong>open-set</strong>, <strong>video understanding</strong>, <strong>vision-language</strong> and <strong>3D vision</strong>. Recently, I am particularly interested in multi-modal LLM and generative AI for complex visual understanding and reasoning problems. Feel free to reach out to me if you are interested in collaboration. -->
	</p>

<!-- 	<p style="text-align:justify;font-size:130%;"><font color="#E74C3C"><strong>I am open to research positions from academia and industry.</strong></font></p> -->


<h2>News [<img src="./index_files//update.gif">]</h2>
	<div  style="overflow-y: scroll; height:200px;">
	<table border="1" style="border-width: 0px;" width="1050">
	<tbody>
	<tr>
	<td style="border-style: none; border-width: medium;">
    <ul>
	    	               <li type="circle">2025.02: One first-author paper is accepted by <strong>CVPR 2025</strong>.</li> 
	               <li type="circle">2025.01: Start my new journey at <strong>UIC</strong>, Chicago, IL.</li> 
	    		<li type="circle">2024.04: One first-author paper is accepted by <strong>ICMR 2024</strong>.</li>
	    		<li type="circle">2023.12: One co-author paper is accepted by <strong>AAAI 2024</strong>.</li>
	    		<li type="circle">2023.02: Two co-author paper is accepted by <strong>CVPR 2023</strong>.</li>
	    		<li type="circle">2022.05: One first-author paper is accepted by <strong>CVPR Workshop 2022</strong>.</li>
	    <li type="circle">2021.09: Start my new journey at <strong>IIT</strong>, Chicago, IL.</li> 
	   		 <li type="circle">2019.05: One first-author paper is accepted by <strong>SIGIR 2019</strong>.</li>
<!-- 		<li type="circle">2024.03: I am honored to be selected to present in <a href="https://cvpr.thecvf.com/Conferences/2024/CallForDoctoralConsortium">CVPR 2024 Doctoral Consortium!</a></li>
		<li type="circle">2024.02: I successfuly passed the MSU PhD Comprehensive Exam, being a Ph.D. candidate!</li>
		<li type="circle">2023.07: One paper is accepted by <strong>ICCV 2023</strong>.</li>
    	<li type="circle">2023.05: I am invited to deliver a talk on open-set recognition at the the 2nd MSU-ND workshop.</li>
		<li type="circle">2023.02: I will be a research intern at <strong>NEC Laboratories America, Inc.</strong> (Princeton, NJ) in this summer.</li>
		<li type="circle">2023.02: One co-authored paper is accepted by <strong>CVPR 2023</strong>.</li>
    	<li type="circle">2022.08: I started my second journey of Ph.D. study at the CSE department at <strong>MSU</strong>!</li>
    	<li type="circle">2022.07: One co-authored paper is accepted by <strong>ECCV 2022</strong>.</li>
    	<li type="circle">2022.06: Start my internship at <strong>OPPO U.S. Research Center</strong> at Palo Alto, CA. (on-site)</li>
    	<li type="circle">2022.05: I attended the conference <strong>ICRA 2022</strong> on-site at Philadelphia, PA.</li>
    	<li type="circle">2022.04: I received the <strong>CVPR 2022 Travel Award</strong> to attend the conference at New Orleans, LA.</li>
		<li type="circle">2022.03: One paper is accepted by <strong>CVPR 2022</strong> for <strong>Oral</strong> presentation!</li>
    	<li type="circle">2021.10: One co-authored paper is accepted by <strong>BMVC 2021</strong>.</li>
    	<li type="circle">2021.07: Two papers are accepted by <strong>ICCV 2021</strong>, with one paper for <strong>Oral</strong> presentation!</li>
		<li type="circle">2021.06: Start my internship at <strong>Apple Inc.</strong>, 3D Vision Team at Apple Maps. (remote)</li>
		<li type="circle">2021.04: One co-authored paper is accepted by <strong>IJCNN 2021</strong>.</li>
		<li type="circle">2020.07: Two papers are accepted by <strong>ACM MM 2020</strong> (one co-authored).</li>
		<li type="circle">2020.07: One co-authored paper is accepted by <strong>ECCV 2020</strong>.</li>
		<li type="circle">2020.06: One paper is accepted by <strong>IROS 2020</strong>.</li>
		<li type="circle">2020.06: One co-authored paper is accepted by <strong>ICPR 2020</strong>.</li>
		<li type="circle">2020.05: I passed the <strong>Ph.D. Research Potential Assessment</strong>!</li>
		<li type="circle">2019.08: Start my new journey at <strong>RIT</strong>, Rochester, NY.</li> -->
    </ul><br>
    </td>
	</tr>
	</tbody>
	</table>
	</div>

<h2>Selected Publications</h2>
	
<!--   <h3>Preprints</h3>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_emola.png);"></div>
	<div class="row-text">
		Facial Affective Behavior Analysis with Instruction Tuning<br/>
		Yifan Li, Anh Dao, <span class="bold">Wentao Bao</span>, Zhen Tan, Tianlong Chen, Huan Liu, Yu Kong<br/>
	    <span class="italic">Preprint, 2024</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2404.05052.pdf">arXiv</a>
	  <a class="btn" href="bibs/emola.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_plid.png);"></div>
	<div class="row-text">
		Prompting Language-Informed Distribution for Compositional Zero-Shot Learning<br/>
		<span class="bold">Wentao Bao</span>, Lichang Chen, Heng Huang, Yu Kong<br/>
	    <span class="italic">Preprint, 2023</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2305.14428.pdf">arXiv</a>
	  <a class="btn" href="bibs/plid.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_fineosr.png);"></div>
	<div class="row-text">
		Latent Space Energy-based Model for Fine-grained Open Set Recognition<br/>
		<span class="bold">Wentao Bao</span>, Qi Yu, Yu Kong<br/>
	    <span class="italic">Preprint, 2023</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2309.10711.pdf">arXiv</a>
	  <a class="btn" href="bibs/fineosr.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_gencnp.png);"></div>
	<div class="row-text">
		On Model Explanations with Transferable Neural Pathways<br/>
		Xinmiao Lin, <span class="bold">Wentao Bao</span>, Qi Yu, Yu Kong<br/>
		<span class="italic">Preprint, 2023</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2309.09887.pdf">arXiv</a>
	  <a class="btn" href="bibs/gencnp.txt">BibTeX</a>
	</div>
  </div> -->


  <h3>Conferences</h3>
	<!--p0 -->
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/icmr2024.png);"></div>
	<div class="row-text">Enhancing Dance-to-Music Generation via Negative Conditioning Latent Diffusion Model<br/>
		<span class="bold">Changchang Sun</span>, Gaowen Liu,  Charles Fleming, Yan Yan<br/>
		<span class="italic">Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025</span><br/>
<!-- 		files/pubs/ICMR_icmrfp367.pdf -->
<!-- 	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/ICCV2023/papers/Bao_Uncertainty-aware_State_Space_Transformer_for_Egocentric_3D_Hand_Trajectory_Forecasting_ICCV_2023_paper.pdf">PDF</a>  -->
<!-- 		<a class="btn btn-orange" href="https://github.com/oppo-us-research/USST">Code</a> -->
<!-- 		<a class="btn btn-orange" href="https://actionlab-cv.github.io/EgoHandTrajPred">Project</a> -->
<!-- 		<a class="btn btn-red" href="https://arxiv.org/pdf/2307.08243.pdf">arXiv</a> -->
<!-- 	  <a class="btn" href="bibs/icmr2024.txt">BibTeX</a> -->
	</div>
  </div>
	
<!--p1 -->
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/icmr2024.png);"></div>
	<div class="row-text">DCT: Divide-and-Conquer Transformer Network with Knowledge Transfer for Query-driven HOI Detection<br/>
		<span class="bold">Changchang Sun</span>, Bin Duan, Hugo Latapie, Gaowen Liu, Yan Yan<br/>
		<span class="italic">ACM International Conference on Multimedia Retrieval  (<strong>ICMR</strong>), 2024</span><br/>
<!-- 		files/pubs/ICMR_icmrfp367.pdf -->
<!-- 	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/ICCV2023/papers/Bao_Uncertainty-aware_State_Space_Transformer_for_Egocentric_3D_Hand_Trajectory_Forecasting_ICCV_2023_paper.pdf">PDF</a>  -->
<!-- 		<a class="btn btn-orange" href="https://github.com/oppo-us-research/USST">Code</a> -->
<!-- 		<a class="btn btn-orange" href="https://actionlab-cv.github.io/EgoHandTrajPred">Project</a> -->
<!-- 		<a class="btn btn-red" href="https://arxiv.org/pdf/2307.08243.pdf">arXiv</a> -->
<!-- 	  <a class="btn" href="bibs/icmr2024.txt">BibTeX</a> -->
	</div>
  </div>
<!--p2 -->
	<div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/AAAI24.png);"></div>
	<div class="row-text">
		WaveFormer: Wavelet Transformer for Noise-Robust Video Inpainting<br/>
		Zhiliang Wu, <span class="bold">Changchang Sun</span>, Hanyu Xuan, Gaowen Liu, Yan Yan<br/>
		<span class="italic">AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2024</span><br/>
	    <a class="btn btn-red" href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=bCxWjjYAAAAJ&sortby=pubdate&citation_for_view=bCxWjjYAAAAJ:WF5omc3nYNoC">PDF</a>
<!-- 		<a class="btn btn-orange" href="https://github.com/libingzeng/landmark_consistent_plugin">Code</a> -->
<!-- 		<a class="btn btn-orange" href="https://libingzeng.github.io/projects/landmark/landmark.html">Project</a> -->
	    <a class="btn" href="bibs/AAAI24.txt">BibTeX</a>
	</div>
  </div>
<!--p3 -->	
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/CVPR23_1.png);"></div>
	<div class="row-text">
		Deep stereo video inpainting<br/>
		Zhiliang Wu, <span class="bold">Changchang Sun</span>, Hanyu Xuan, Yan Yan<br/>
		<span class="italic">IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023</span><br/>
	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Deep_Stereo_Video_Inpainting_CVPR_2023_paper.pdf">PDF</a>
<!-- 		<a class="btn btn-orange" href="https://github.com/libingzeng/landmark_consistent_plugin">Code</a> -->
<!-- 		<a class="btn btn-orange" href="https://libingzeng.github.io/projects/landmark/landmark.html">Project</a> -->
	    <a class="btn" href="bibs/cvpr_1.txt">BibTeX</a>
	</div>
  </div>
<!--p4 -->
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/CVPR23_2.png);"></div>
	<div class="row-text">
		Semi-supervised video inpainting with cycle consistency constraints<br/>
		Zhiliang Wu, Hanyu Xuan, <span class="bold">Changchang Sun</span>, Weili Guan, Kang Zhang, Yan Yan
		<br/>
		<span class="italic">IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023</span><br/>
	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Semi-Supervised_Video_Inpainting_With_Cycle_Consistency_Constraints_CVPR_2023_paper.pdf">PDF</a>
<!-- 		<a class="btn btn-red" href="https://arxiv.org/pdf/2208.11113.pdf">arXiv</a> -->
<!-- 		<a class="btn btn-orange" href="https://github.com/YUZ128pitt/Towards-OpenVAD">Code</a> -->
	    <a class="btn" href="bibs/cvpr_2.txt">BibTeX</a>
	</div>
  </div>
	<!--p5 -->
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/WACV23.png);"></div>
	<div class="row-text">
		Few-shot medical image segmentation with cycle-resemblance attention<br/>
		Hao Ding, <span class="bold">Changchang Sun</span>, Hao Tang, Dawen Cai, Yan Yan
		<br/>
		<span class="italic">IEEE/CVF Winter Conference on Applications of Computer Vision (<strong>WACV</strong>), 2023</span><br/>
	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/WACV2023/papers/Ding_Few-Shot_Medical_Image_Segmentation_With_Cycle-Resemblance_Attention_WACV_2023_paper.pdf">PDF</a>
<!-- 		<a class="btn btn-red" href="https://arxiv.org/pdf/2208.11113.pdf">arXiv</a> -->
<!-- 		<a class="btn btn-orange" href="https://github.com/YUZ128pitt/Towards-OpenVAD">Code</a> -->
	    <a class="btn" href="bibs/wacv23.txt">BibTeX</a>
	</div>
  </div>
<!--p6 -->
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/CVPR22.png);"></div>
	<div class="row-text">
		Deep normalized cross-modal hashing with bi-direction relation reasoning<br/>
		 <span class="bold">Changchang Sun</span>, Hugo Latapie, Gaowen Liu, Yan Yan
		<br/>
		<span class="italic"> IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<strong>CVPR</strong>), 2022</span><br/>
	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/CVPR2022W/ODRUM/papers/Sun_Deep_Normalized_Cross-Modal_Hashing_With_Bi-Direction_Relation_Reasoning_CVPRW_2022_paper.pdf">PDF</a>
<!-- 		<a class="btn btn-red" href="https://arxiv.org/pdf/2208.11113.pdf">arXiv</a> -->
<!-- 		<a class="btn btn-orange" href="https://github.com/YUZ128pitt/Towards-OpenVAD">Code</a> -->
	    <a class="btn" href="bibs/cvpr22.txt">BibTeX</a>
	</div>
  </div>
 <!--p7 -->
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/SIGIR19.png);"></div>
	<div class="row-text">
		Supervised hierarchical cross-modal hashing<br/>
		<span class="bold">Changchang Sun</span>, Xuemeng Song, Fuli Feng, Wayne Xin Zhao, Hao Zhang, Liqiang Nie
		<br/>
		<span class="italic"> ACM SIGIR conference on research and development in information retrieval (<strong>SIGIR</strong>), 2019</span><br/>
	    <a class="btn btn-red" href="https://dl.acm.org/doi/pdf/10.1145/3331184.3331229">PDF</a>
<!-- 		<a class="btn btn-red" href="https://arxiv.org/pdf/2208.11113.pdf">arXiv</a> -->
		<a class="btn btn-orange" href="https://drive.google.com/drive/folders/1v1qu3AwSPucmjfuw2r81ORD9HjyK8Hdr">Code</a>
	    <a class="btn" href="bibs/sigir19.txt">BibTeX</a>
	</div>
  </div>

  <h3>Journals</h3>
 <!--p1 -->
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/TCSVT23.png);"></div>
	<div class="row-text">
		Divide-and-conquer completion network for video inpainting<br/>
		Zhiliang Wu, <span class="bold">Changchang Sun</span>, Hanyu Xuan, Kang Zhang, Yan Yan
		<br/>
		<span class="italic">IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), 2023</span><br/>
	    <a class="btn btn-red" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9967838">PDF</a>
<!-- 		<a class="btn btn-red" href="https://arxiv.org/pdf/2208.11113.pdf">arXiv</a> -->
<!-- 		<a class="btn btn-orange" href="https://drive.google.com/drive/folders/1v1qu3AwSPucmjfuw2r81ORD9HjyK8Hdr">Code</a> -->
	    <a class="btn" href="bibs/tcsvt23.txt">BibTeX</a>
		</div>
  </div>
 <!--p2 -->
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/TKDE23.png);"></div>
	<div class="row-text">
		MM-FRec: Multi-modal enhanced fashion item recommendation<br/>
		Xuemeng Song, Chun Wang, <span class="bold">Changchang Sun</span>, Shanshan Feng, Min Zhou, Liqiang Nie
		<br/>
		<span class="italic">
IEEE Transactions on Knowledge and Data Engineering (<strong>TKDE</strong>), 2023</span><br/>
	    <a class="btn btn-red" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10100905">PDF</a>
<!-- 		<a class="btn btn-red" href="https://arxiv.org/pdf/2208.11113.pdf">arXiv</a> -->
		<a class="btn btn-orange" href="https://outfitrec.wixsite.com/mm-frec">Code</a>
	    <a class="btn" href="bibs/tkde23.txt">BibTeX</a>
		</div>
  </div>
	
<!--
  <h3>Patents</h3>
  <ul>
	<li type="disc">
    Jiangping Chen, <strong>Wentao Bao</strong>, Yaqi Liu. Self-adaption Indoor Parking Navigation and Automatic
Parking System and Method based on Bluetooth Low Energy (BLE), <strong>China Invention Patent (Authorized)</strong>,
Application No. CN201710791726.5, Publication No. CN107605219A, Publication Date Jan. 19th, 2018.
	</li>
  </ul>	
-->

<h2>Selected Awards & Honors</h2>
  <h3>Awards</h3>
    <ul>
    <li type="disc"> <strong>CVPR 2022 Student Travel Award</strong> for in-person conference at New Orleans, USA, 2022.
	<li type="disc"> <strong>SIGIR 2019 Student Travel Award</strong> for in-person conference at Paris, France, 2019.
<!--     <li type="disc"> <strong>AAAI 2020 Travel Award</strong> for in-person conference at New York, USA, 2020. -->
	<br>
    </ul>

<!--   <h3>Honors</h3>
	<ul>
	<li type="disc"> Third Class Scholarship of Shandong University, 2020.</li>
	<li type="disc"> Dean Scholarship of School of Computer Science and Technology, Shandong University, 2019.</li>
	<li type="disc"> Excellent Postgraduate, Shandong University, 2019.</li>
	<li type="disc">  Second Class Scholarship of Shandong University, 2019.</li>
	<li type="disc"> Excellent Freshman Scholarship of Shandong University, 2018.</li>
    <li type="disc"> Third Class Scholarship of Shandong University, 2015 & 2016 & 2017. </li>
	</ul>	 -->
	

<h2>Academic Services</h2>
  <h3>Conference Reviewer</h3>
    <ul>
<li type="disc">Annual Conference on Neural Information Processing Systems (NeurIPS): <a href="https://neurips.cc/">2024</a> </li>
    <li type="disc">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR): <a href="https://cvpr.thecvf.com/Conferences/2024">2024</a> </li>
	<li type="disc">ACM Conference on Multimedia (ACMMM): <a href="https://2024.acmmm.org/">2024</a> </li>
<li type="disc">ACM Web Conference (WebConf): <a href="https://www2024.thewebconf.org/">2024</a> </li>
<!-- 	    
    <li type="disc">IEEE/CVF International Conference on Computer Vision (ICCV): <a href="http://iccv2021.thecvf.com">2021</a></li>
    <li type="disc">European Conference on Computer Vision (ECCV): <a href="https://eccv2022.ecva.net">2022</a>, <a href="https://eccv.ecva.net/Conferences/2024">2024</a></li>
    <li type="disc">International Joint Conference on Artificial Intelligence (IJCAI): <a href="https://ijcai-23.org">2023</a></li>
	<li type="disc">ACM International Conference on Multimedia (ACM MM): <a href="https://2019.acmmm.org">2019</a>, <a href="https://2020.acmmm.org">2020</a>, <a href="https://2021.acmmm.org">2021</a>, <a href="https://2022.acmmm.org">2022</a>, <a href="https://2023.acmmm.org">2023</a></li>
    <li type="disc">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV): <a href="https://wacv2023.thecvf.com">2023</a>, <a href="https://wacv2024.thecvf.com">2024</a></li>
	<li type="disc">IEEE International Conference on Multimedia and Expo (ICME): <a href="https://2024.ieeeicme.org">2024</a> </li>
    <li type="disc">IEEE International Conference on Robotics and Automation (ICRA): <a href="http://www.icra2021.org">2021</a></li>
    <li type="disc">IEEE International Conference on Web Services (ICWS): <a href="https://conferences.computer.org/icws/2021">2021</a></li>
    <li type="disc">IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI): <a href="https://mfi2020.org">2020</a></li> -->
	</ul>
	
  <h3>Journal Reviewer</h3>
    <ul>
<!-- 	    	        <li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE Transactions on Pattern Analysis and Machine In/telligence (TPAMI)</a>. </li> -->
	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69">IEEE Transactions on Knowledge and Data Engineering (TKDE)</a>. </li>
	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE Transactions on Multimedia (TMM)</a>. </li>
	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</a>. </li>
	    	<li type="disc"> <a href="https://www.journals.elsevier.com/information-sciences">Elsevier: Information Sciences (IS)</a>.</li>
	<li type="disc"> <a href="https://www.sciencedirect.com/journal/neurocomputing">Elsevier: Neurocomputing  (IS)</a>.</li>

	    <!--     <li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</a>. </li> -->
<!-- 	    	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE Transactions on Image Processing (TIP)</a>. </li> -->

	</ul>
	    
  <h3>Membership</h3>
	<ul>
	<li type="disc"> IEEE Student Member.</li>
	<li type="disc"> ACM Student Member.</li>
	</ul>
	
<!--   <h3>Volunteer</h3>
	<ul>
	<li type="disc"> <a href="https://aaai.org/Conferences/AAAI-20/"> Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)</a>, Feb. 7-12, 2020, New York, USA.</li>
	</ul> -->
	
  <h3>Teaching</h3>
	<ul>
		<li type="disc">Teaching Assistant, IIT CS-536: Machine Learning, SS2022.</li>
		<li type="disc">Teaching Assistant, Shandong University: Fundamentals of Electric Circuits, SS2019 & SS2020 & SS2021.</li>
	</ul>
	
<!--   <h3>Academic Talks</h3>
  	<ul>
  		<li type="disc">2023.05.13: Delivering a talk at <a href="https://hal.cse.msu.edu/workshop/2nd-msu-nd-workshop/">the 2nd MSU-ND Computer Vision and Biometrics Workshop</a>, introducing on Evidential Deep Learning for Open-Set Action Recognition</li>
  	</ul>
  	<ul>
  		<li type="disc">2021.08.20 & 2021.09.16: Delivering two academic talks in Chinese media <a href="https://www.bilibili.com/video/BV1Gq4y1D7At">Jishi</a> and <a href="https://www.bilibili.com/video/BV1DM4y1G7Nx">TechBeat</a>, introducing our recent ICCV Oral paper.</li>
  	</ul>
	<ul>
		<li type="disc">2019.07.18: Delivering an academic talk in the 2019 SIGIR C.</li>
	</ul> -->
<hr>

<table cellpadding="0px">
	<tbody>
		<tr>
			<td width="720px">
			<div id="clustrmaps-widget"></div>
<!-- 				<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=7seMHMuQZlvELLsuK6wd30IX5cz7U58mGsA8iV8s6_o"></script></script>
				</script> -->
					<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=vJBld2HuonAH0YFQwFFTeeh1n9-tvDa2zOi6qWkezJk&cl=ffffff&w=a"></script>
			<div class="jvectormap-tip"></div>
			</td>
			<td valign="top">
				<div style="clear:both;">
<!-- 				<p align="right"><font size="2">Last Updated on Apr. 25, 2024 -->
				<p><font size="2">Last Updated on March 31, 2025
					<br>
				Published with <a href="https://pages.github.com/">GitHub Pages</a>, webpage template borrows from <a href="https://cogito2012.github.io/homepage/"> Wentao Bao</a> with a big thanks.
				</font></p>
				</div>
<!-- 				<div style="clear: both;">
				<p align="right"><font size="5"><img src="./index_files//raccoon.gif"></font></p>
				</div> -->
			</td>
		</tr>
	</tbody>
</table>

</body>
</html>
