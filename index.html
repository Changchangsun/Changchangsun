<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">	
	<title>Changchang Sun</title>
	<meta content=Changchang Sun, changchangsun.github.io/Changchangsun" name="keywords">
	<link rel="stylesheet" href="./index_files/jemdoc.css" type="text/css">
	<script async="" src="http://www.google-analytics.com/analytics.js"></script>
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
		ga('create', 'UA-66888300-1', 'auto');
		ga('send', 'pageview');
	</script>
	<script type="text/javascript" src="./index_files/jquery-1.12.4.min.js"></script>
	<style>
	a {color: #2471a3; text-decoration: none;}
	a:hover {color: #5499c7;}
	a.btn {background-color: #2471a3; color: #fff; font-size: 12px; margin-top: 4px; display: inline-block; padding: 0 4px; border-radius: 2px; line-height: 1.5em;}
	a.btn:hover {background-color: #174e74;}
	a.btn.btn-red {background-color: #d63a3a;}
	a.btn.btn-red:hover {background-color: #a02727;}
	a.btn.btn-orange {background-color: #e2700c;}
	a.btn.btn-orange:hover {background-color: #c46009;}
	a.btn.btn-dark {background-color: #345;}
	a.btn.btn-dark:hover {background-color: #234;}
	p {line-height: 1.5em;}
	.nobreak {white-space: nowrap;}
	.noselect {-webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none;}
	.bold {font-weight: bold;}
	.italic {font-style: italic;}
	.bulletpoints {line-height: 1.5em;}
	.row {box-sizing: border-box;}
	.row-media {display: block; float: left; width: 180px; height: 90px; background-position: center; background-size: contain; background-repeat: no-repeat; border-radius: 6px; border: 1px solid #def;}
	.row-text {display: block; float: left; margin-left: 16px; line-height: 1.5em; max-width: 662px;}
	.row-text span {line-height: inherit;}
	.clearfix {content: ""; clear: both; display: table;}
	.publication {margin-bottom: 32px; margin-left: 16px;}
	.press {width: 100px; height: 80px; border: 1px solid #def; margin-right: 12px; background-size: cover;}  
	.img-contain {background-size: contain !important;}
	.footer {background-color: #345; width: 100%}
	.footer-content {color: #fff; font-size: 10px; padding: 6px 0; max-width: 900px; margin: auto;}

	@media only screen and (max-width: 1150px) {
		.header-profile-picture, .header-text {display: block; margin: auto; text-align: center;}
		.header-profile-picture {margin-bottom: 12px; width: 140px; height: 140px;}
		body {font-size: 18px;}
		a.btn {font-size: 14px; padding: 2px 6px;}
	}

	@media only screen and (max-width: 900px) {
		.publication {margin-bottom: 46px;}
		.publication .row-media {width: 260px; height: 130px; margin: auto; margin-bottom: 12px; display: block;}
		.publication .row-text {display: block; width: 100%; margin-left: 0;}
		.press {display: block;}
	}
    </style>
</head>


<body>
<div id="layout-content" style="margin-top:25px">

<table cellpadding="11px">
	<tbody>
		<tr>
			<td width="720px">
				<div id="toptitle">
					<h1>Changchang Sun (孙畅畅) &nbsp; </h1>
				</div>
                <h3>Ph.D. Student</h3>       
				<p>
					<!-- <a href="https://iitcvmlab.github.io/">CVM Lab @ IIT</a><br>  -->
					<a href="https://iitcvmlab.github.io/">CVM Lab @ IIT</a><br> 
					<a href="https://www.iit.edu/computer-science">Department of Computer Science</a><br>
					<a href="https://www.iit.edu/">Illinois Institute of Technology</a><br>
					10 West 35th Street, Chicago, IL 60616, U.S.A <br>
					<br>
					Email:  sunchangchang123 at gmail dot com<br>
					<br>
<!-- 					<a href="./files/Wentao-Bao.pdf"> <img src="./files/logo-cv.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a> -->
					<a href="https://github.com/Changchangsun"> <img src="./files/logo-github.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
<!-- 					<a href="https://www.zhihu.com/people/Cogito2012"> <img src="./files/logo-zhihu.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a> -->
					<a href="https://scholar.google.com/citations?user=bCxWjjYAAAAJ&hl=zh-CN&oi=ao"> <img src="./files/logo-googlescholar.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
<!-- 					<a href="https://www.linkedin.com/in/wentao-bao-a59b88125"> <img src="./files/logo-linkin.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a> -->
                </p>
			</td>
			<td valign="middle">
				<img src="./files/scc.jpg" border="0" width="180"><br><br>
			</td>
		</tr>
	</tbody>
</table>

<h2>About Me</h2> 
	<p style="text-align:justify;">I am a third-year Ph.D. student (2021-) in the <a href="https://iitcvmlab.github.io/">Computer Vision and Multimedia Laboratory (CVMLab)</a>
	at the <a href="https://www.iit.edu/">Illinois Institute of Technology (IIT)</a>, supervised by Assistant Professor <a href="https://tomyan555.github.io/">Yan Yan</a>. 
Before joining CVMLab, I received my Master and Bacherlor degrees from <a href="https://www.en.sdu.edu.cn/">Computer Science and Technology, Shandong University</a> in 2021 and 2018, supervised by Associate Professor <a href="https://xuemengsong.github.io/">Xuemeng Song</a>,
    and co-supervised by Professor <a href="https://liqiangnie.github.io/index.html"{>Liqiang Nie</a>.
<!-- 		I have research internship collaborations with excellent industrial researchers from Apple, OPPO US Research Center, and NEC Lab America.  -->
	</p>
	<p>I currently work on computer vision like human-object interaction detection, cross-modal generation and retrieval. During the master's degree, I worked on information retrieval and machine learning.
<!-- 	<p style="text-align:justify;"><strong>I develop AI to understand the open visual world</strong>. To achieve this goal, I am broadly interested in using images/videos/text to solve real-world challenges including the visual recognition, prediction, understanding, and reasoning. My research works are related to <strong>open-set</strong>, <strong>video understanding</strong>, <strong>vision-language</strong> and <strong>3D vision</strong>. Recently, I am particularly interested in multi-modal LLM and generative AI for complex visual understanding and reasoning problems. Feel free to reach out to me if you are interested in collaboration. -->
	</p>

<!-- 	<p style="text-align:justify;font-size:130%;"><font color="#E74C3C"><strong>I am open to research positions from academia and industry.</strong></font></p> -->


<h2>News [<img src="./index_files//update.gif">]</h2>
	<div  style="overflow-y: scroll; height:200px;">
	<table border="1" style="border-width: 0px;" width="1050">
	<tbody>
	<tr>
	<td style="border-style: none; border-width: medium;">
    <ul>
	    		<li type="circle">2024.04: One first-author paper is accepted by <strong>ICMR 2024</strong>.</li>
	    		<li type="circle">2023.12: One co-author paper is accepted by <strong>AAAI 2024</strong>.</li>
	    		<li type="circle">2023.02: Two co-author paper is accepted by <strong>CVPR 2023</strong>.</li>
	    		<li type="circle">2022.05: One first-author paper is accepted by <strong>CVPR Workshop 2022</strong>.</li>
	    <li type="circle">2021.09: Start my new journey at <strong>IIT</strong>, Chicago, IL.</li> 
	   		 <li type="circle">2019.05: One first-author paper is accepted by <strong>SIGIR 2019</strong>.</li>
<!-- 		<li type="circle">2024.03: I am honored to be selected to present in <a href="https://cvpr.thecvf.com/Conferences/2024/CallForDoctoralConsortium">CVPR 2024 Doctoral Consortium!</a></li>
		<li type="circle">2024.02: I successfuly passed the MSU PhD Comprehensive Exam, being a Ph.D. candidate!</li>
		<li type="circle">2023.07: One paper is accepted by <strong>ICCV 2023</strong>.</li>
    	<li type="circle">2023.05: I am invited to deliver a talk on open-set recognition at the the 2nd MSU-ND workshop.</li>
		<li type="circle">2023.02: I will be a research intern at <strong>NEC Laboratories America, Inc.</strong> (Princeton, NJ) in this summer.</li>
		<li type="circle">2023.02: One co-authored paper is accepted by <strong>CVPR 2023</strong>.</li>
    	<li type="circle">2022.08: I started my second journey of Ph.D. study at the CSE department at <strong>MSU</strong>!</li>
    	<li type="circle">2022.07: One co-authored paper is accepted by <strong>ECCV 2022</strong>.</li>
    	<li type="circle">2022.06: Start my internship at <strong>OPPO U.S. Research Center</strong> at Palo Alto, CA. (on-site)</li>
    	<li type="circle">2022.05: I attended the conference <strong>ICRA 2022</strong> on-site at Philadelphia, PA.</li>
    	<li type="circle">2022.04: I received the <strong>CVPR 2022 Travel Award</strong> to attend the conference at New Orleans, LA.</li>
		<li type="circle">2022.03: One paper is accepted by <strong>CVPR 2022</strong> for <strong>Oral</strong> presentation!</li>
    	<li type="circle">2021.10: One co-authored paper is accepted by <strong>BMVC 2021</strong>.</li>
    	<li type="circle">2021.07: Two papers are accepted by <strong>ICCV 2021</strong>, with one paper for <strong>Oral</strong> presentation!</li>
		<li type="circle">2021.06: Start my internship at <strong>Apple Inc.</strong>, 3D Vision Team at Apple Maps. (remote)</li>
		<li type="circle">2021.04: One co-authored paper is accepted by <strong>IJCNN 2021</strong>.</li>
		<li type="circle">2020.07: Two papers are accepted by <strong>ACM MM 2020</strong> (one co-authored).</li>
		<li type="circle">2020.07: One co-authored paper is accepted by <strong>ECCV 2020</strong>.</li>
		<li type="circle">2020.06: One paper is accepted by <strong>IROS 2020</strong>.</li>
		<li type="circle">2020.06: One co-authored paper is accepted by <strong>ICPR 2020</strong>.</li>
		<li type="circle">2020.05: I passed the <strong>Ph.D. Research Potential Assessment</strong>!</li>
		<li type="circle">2019.08: Start my new journey at <strong>RIT</strong>, Rochester, NY.</li> -->
    </ul><br>
    </td>
	</tr>
	</tbody>
	</table>
	</div>

<!-- <h2>Selected Publications</h2> -->
	<h2>Publications</h2>
	
<!--   <h3>Preprints</h3>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_emola.png);"></div>
	<div class="row-text">
		Facial Affective Behavior Analysis with Instruction Tuning<br/>
		Yifan Li, Anh Dao, <span class="bold">Wentao Bao</span>, Zhen Tan, Tianlong Chen, Huan Liu, Yu Kong<br/>
	    <span class="italic">Preprint, 2024</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2404.05052.pdf">arXiv</a>
	  <a class="btn" href="bibs/emola.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_plid.png);"></div>
	<div class="row-text">
		Prompting Language-Informed Distribution for Compositional Zero-Shot Learning<br/>
		<span class="bold">Wentao Bao</span>, Lichang Chen, Heng Huang, Yu Kong<br/>
	    <span class="italic">Preprint, 2023</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2305.14428.pdf">arXiv</a>
	  <a class="btn" href="bibs/plid.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_fineosr.png);"></div>
	<div class="row-text">
		Latent Space Energy-based Model for Fine-grained Open Set Recognition<br/>
		<span class="bold">Wentao Bao</span>, Qi Yu, Yu Kong<br/>
	    <span class="italic">Preprint, 2023</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2309.10711.pdf">arXiv</a>
	  <a class="btn" href="bibs/fineosr.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_gencnp.png);"></div>
	<div class="row-text">
		On Model Explanations with Transferable Neural Pathways<br/>
		Xinmiao Lin, <span class="bold">Wentao Bao</span>, Qi Yu, Yu Kong<br/>
		<span class="italic">Preprint, 2023</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2309.09887.pdf">arXiv</a>
	  <a class="btn" href="bibs/gencnp.txt">BibTeX</a>
	</div>
  </div> -->


  <h3>Conferences</h3>

  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/icmr2024.png);"></div>
	<div class="row-text">DCT: Divide-and-Conquer Transformer Network with Knowledge Transfer for Query-driven HOI Detection<br/>
		<span class="bold">Changchang Sun</span>, Bin Duan, Hugo Latapie, Gaowen Liu, Yan Yan<br/>
		<span class="italic">ACM International Conference on Multimedia Retrieval  (<strong>ICMR</strong>), 2024</span><br/>
<!-- 		files/pubs/ICMR_icmrfp367.pdf -->
<!-- 	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/ICCV2023/papers/Bao_Uncertainty-aware_State_Space_Transformer_for_Egocentric_3D_Hand_Trajectory_Forecasting_ICCV_2023_paper.pdf">PDF</a>  -->
<!-- 		<a class="btn btn-orange" href="https://github.com/oppo-us-research/USST">Code</a> -->
<!-- 		<a class="btn btn-orange" href="https://actionlab-cv.github.io/EgoHandTrajPred">Project</a> -->
<!-- 		<a class="btn btn-red" href="https://arxiv.org/pdf/2307.08243.pdf">arXiv</a> -->
<!-- 	  <a class="btn" href="bibs/icmr2024.txt">BibTeX</a> -->
	</div>
  </div>

	<div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/AAAI24.png);"></div>
	<div class="row-text">
		WaveFormer: Wavelet Transformer for Noise-Robust Video Inpainting<br/>
		Zhiliang Wu, <span class="bold">Changchang Sun</span>, Hanyu Xuan, Gaowen Liu, Yan Yan<br/>
		<span class="italic">AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2024</span><br/>
	    <a class="btn btn-red" href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=bCxWjjYAAAAJ&sortby=pubdate&citation_for_view=bCxWjjYAAAAJ:WF5omc3nYNoC">PDF</a>
<!-- 		<a class="btn btn-orange" href="https://github.com/libingzeng/landmark_consistent_plugin">Code</a> -->
<!-- 		<a class="btn btn-orange" href="https://libingzeng.github.io/projects/landmark/landmark.html">Project</a> -->
	    <a class="btn" href="bibs/AAAI24.txt">BibTeX</a>
	</div>
  </div>
	
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/CVPR23_1.png);"></div>
	<div class="row-text">
		Deep stereo video inpainting<br/>
		Zhiliang Wu, <span class="bold">Changchang Sun</span>, Hanyu Xuan, Yan Yan<br/>
		<span class="italic">IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023</span><br/>
	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Deep_Stereo_Video_Inpainting_CVPR_2023_paper.pdf">PDF</a>
<!-- 		<a class="btn btn-orange" href="https://github.com/libingzeng/landmark_consistent_plugin">Code</a> -->
<!-- 		<a class="btn btn-orange" href="https://libingzeng.github.io/projects/landmark/landmark.html">Project</a> -->
	    <a class="btn" href="bibs/cvpr_1.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/CVPR23_2.png);"></div>
	<div class="row-text">
		Semi-supervised video inpainting with cycle consistency constraints<br/>
		Zhiliang Wu, Hanyu Xuan, <span class="bold">Changchang Sun</span>, Weili Guan, Kang Zhang, Yan Yan
		<br/>
		<span class="italic">IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023</span><br/>
	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Semi-Supervised_Video_Inpainting_With_Cycle_Consistency_Constraints_CVPR_2023_paper.pdf">PDF</a>
<!-- 		<a class="btn btn-red" href="https://arxiv.org/pdf/2208.11113.pdf">arXiv</a> -->
<!-- 		<a class="btn btn-orange" href="https://github.com/YUZ128pitt/Towards-OpenVAD">Code</a> -->
	    <a class="btn" href="bibs/cvpr_2.txt">BibTeX</a>
	</div>
  </div>
 
<!--
  <h3>Patents</h3>
  <ul>
	<li type="disc">
    Jiangping Chen, <strong>Wentao Bao</strong>, Yaqi Liu. Self-adaption Indoor Parking Navigation and Automatic
Parking System and Method based on Bluetooth Low Energy (BLE), <strong>China Invention Patent (Authorized)</strong>,
Application No. CN201710791726.5, Publication No. CN107605219A, Publication Date Jan. 19th, 2018.
	</li>
  </ul>	
-->

<h2>Selected Awards & Honors</h2>
  <h3>Awards</h3>
    <ul>
	<li type="disc"> <strong>CVPR 2024 Travel Award</strong> for presentation in CVPR'24 Doctoral Consortium, Seattle, USA, 2024.</li>
    <li type="disc"> <strong>CVPR 2022 Travel Award</strong> for in-person conference at New Orleans, USA, 2022.
    <li type="disc"> <strong>AAAI 2020 Travel Award</strong> for in-person conference at New York, USA, 2020.
    <li type="disc"> <strong>Postgraduate Academic Innovation Award</strong> from Wuhan University, 2020. </li>
	<li type="disc"> <strong>Grand Prize Winner</strong>, ICME 2018 Grand Challenge on Salient360! Visual Attention Modeling for 360 Content, 2018. </li>
<!--<li type="disc"> <strong>Third-Class Prize</strong>, The 4th National Graduate Contest on Smart-City Technology and Creative Design, Abnormal Event Detection, 2017. </li> -->
	<li type="disc"> <strong>Bronze Award</strong> in Hubei Province, The 2nd China College Students "Internet Plus" Innovation and Entrepreneurship Competition. 2016. </li>
    <li type="disc"> <strong>Second-Class Prize</strong>, The 3rd National Graduate Contest on Smart-City Technology and Creative Design, Abnormal Event Detection. 2016. </li>
    <li type="disc"> <strong>First Prize</strong>, IEEE BigMM 2015 Challenge: "Large-Scale Object Tracking over a Multiple-Camera Network". 2015. </li>	
    <li type="disc"> <strong>Third-Class Prize</strong>, The 14th "Challenge Cup" National Undergraduate Curricular Academic Science and Technology Contest on "Smart City". 2015. </li>
<!--<li type="disc"> <strong>Third prize</strong>, The 13th "SuperMap Cup" National Undergraduate GIS Contest, Cloud Platform and Android Application Development. 2015. </li> -->
	<li type="disc"> <strong>Meritorious Winner</strong>, Mathematical Contest in Modeling (MCM). 2015. </li>
	<li type="disc"> <strong>Second prize</strong>, The 12th "SuperMap Cup" National Undergraduate GIS Contest, Android Application Development. 2014. </li>
	<br>
    </ul>

  <h3>Honors</h3>
	<ul>
	<li type="disc"> Excellent Graduated Student, Wuhan University, 2019. (top 5%)</li>
	<li type="disc"> China National Scholarship, 2018. </li>
    <li type="disc"> The First-class Academic Scholarship, Wuhan University, 2017 & 2018. (top 10%)</li>
	<li type="disc"> Outstanding Postgraduate Student, Wuhan University, 2017 & 2018. (top 10%)</li>
	<li type="disc"> Excellent Graduate Freshman Scholarship of Wuhan University, 2016. (top 10%)</li>
	<li type="disc"> Advanced Individual, Wuhan University, 2016. </li>
	</ul>	
	

<h2>Academic Services</h2>
  <h3>Conference Reviewer</h3>
    <ul>
    <li type="disc">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR): <a href="http://cvpr2021.thecvf.com">2021</a>, <a href="http://cvpr2022.thecvf.com">2022</a>, <a href="https://cvpr2023.thecvf.com">2023</a>, <a href="https://cvpr.thecvf.com/Conferences/2024">2024</a> </li>
    <li type="disc">IEEE/CVF International Conference on Computer Vision (ICCV): <a href="http://iccv2021.thecvf.com">2021</a></li>
    <li type="disc">European Conference on Computer Vision (ECCV): <a href="https://eccv2022.ecva.net">2022</a>, <a href="https://eccv.ecva.net/Conferences/2024">2024</a></li>
    <li type="disc">International Joint Conference on Artificial Intelligence (IJCAI): <a href="https://ijcai-23.org">2023</a></li>
	<li type="disc">ACM International Conference on Multimedia (ACM MM): <a href="https://2019.acmmm.org">2019</a>, <a href="https://2020.acmmm.org">2020</a>, <a href="https://2021.acmmm.org">2021</a>, <a href="https://2022.acmmm.org">2022</a>, <a href="https://2023.acmmm.org">2023</a></li>
    <li type="disc">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV): <a href="https://wacv2023.thecvf.com">2023</a>, <a href="https://wacv2024.thecvf.com">2024</a></li>
	<li type="disc">IEEE International Conference on Multimedia and Expo (ICME): <a href="https://2024.ieeeicme.org">2024</a> </li>
    <li type="disc">IEEE International Conference on Robotics and Automation (ICRA): <a href="http://www.icra2021.org">2021</a></li>
    <li type="disc">IEEE International Conference on Web Services (ICWS): <a href="https://conferences.computer.org/icws/2021">2021</a></li>
    <li type="disc">IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI): <a href="https://mfi2020.org">2020</a></li>
	</ul>
  <h3>Journal Reviewer</h3>
    <ul>
    <li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</a>. </li>
	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE Transactions on Image Processing (TIP)</a>. </li>
	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE Transactions on Multimedia (TMM)</a>. </li>
	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</a>. </li>
	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19">IEEE Transactions on Instrumentation and Measurement (TIM)</a>. </li>
	<li type="disc"> <a href="https://www.ieee-ras.org/publications/ra-l">IEEE Robotics and Automation Letters (RA-L)</a>. </li>
	<li type="disc"> <a href="https://www.journals.elsevier.com/pattern-recognition">Elsevier: Pattern Recognition (PR)</a>. </li>
	<li type="disc"> <a href="https://www.journals.elsevier.com/journal-of-visual-communication-and-image-representation">Elsevier: Journal of Visual Communication and Image Representation (JVCI)</a>. </li>
	<li type="disc"> <a href="https://www.journals.elsevier.com/information-sciences">Elsevier: Information Sciences (IS)</a>.</li>
	<li type="disc"> <a href="https://www.journals.elsevier.com/measurement">Elsevier: Measurement</a>.</li>
	<li type="disc"> <a href="https://www.springer.com/journal/530/">Multimedia System Journal (MMSJ)</a>. </li>
	<li type="disc"> <a href="https://academic.oup.com/comjnl">The Computer Journal</a>. </li>
	</ul>
  <h3>Membership</h3>
	<ul>
	<li type="disc"> IEEE Student Member.</li>
	<li type="disc"> ACM Student Member.</li>
	</ul>
  <h3>Volunteer</h3>
	<ul>
	<li type="disc"> <a href="https://aaai.org/Conferences/AAAI-20/"> Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)</a>, Feb. 7-12, 2020, New York, USA.</li>
	</ul>
  <h3>Teaching</h3>
	<ul>
		<li type="disc">Teaching Assistant, MSU CSE-402: Biometrics and Pattern Recognition, FS2023.</li>
		<li type="disc">Teaching Activities (<a href="./files/slides/IntroDRL.pdf">DRL Intro.</a>), RIT CSCI-631: Foundations of Computer Vision, SS2021 & SS2022.</li>
		<li type="disc">Teaching Activities (<a href="./files/slides/DEAR-Talk.pdf">EDL Intro.</a>), RIT CISC-849: PhD Seminar, FS2021.</li>
	</ul>
  <h3>Academic Talks</h3>
  	<ul>
  		<li type="disc">2023.05.13: Delivering a talk at <a href="https://hal.cse.msu.edu/workshop/2nd-msu-nd-workshop/">the 2nd MSU-ND Computer Vision and Biometrics Workshop</a>, introducing on Evidential Deep Learning for Open-Set Action Recognition</li>
  	</ul>
  	<ul>
  		<li type="disc">2021.08.20 & 2021.09.16: Delivering two academic talks in Chinese media <a href="https://www.bilibili.com/video/BV1Gq4y1D7At">Jishi</a> and <a href="https://www.bilibili.com/video/BV1DM4y1G7Nx">TechBeat</a>, introducing our recent ICCV Oral paper.</li>
  	</ul>
	<ul>
		<li type="disc">2020.11.17: Delivering an academic talk in the 2020 RIT Graduate Virtual Showcase: A Vision Into the Future.</li>
	</ul>
<hr>

<table cellpadding="0px">
	<tbody>
		<tr>
			<td width="720px">
			<div id="clustrmaps-widget"></div>
				<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=7seMHMuQZlvELLsuK6wd30IX5cz7U58mGsA8iV8s6_o"></script></script>
				</script>
			<div class="jvectormap-tip"></div>
			</td>
			<td valign="top">
				<div style="clear:both;">
				<p align="right"><font size="2">Last Updated on Apr. 02, 2024<br>
				Published with <a href="https://pages.github.com/">GitHub Pages</a></font></p>
				</div>
				<div style="clear: both;">
				<p align="right"><font size="5"><img src="./index_files//raccoon.gif"></font></p>
				</div>
			</td>
		</tr>
	</tbody>
</table>

</body>
</html>
